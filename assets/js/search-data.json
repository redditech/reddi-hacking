{
  
    
        "post0": {
            "title": "Messing around with fastai - based on the fastbook content and fastai forum notes",
            "content": "!pip install -Uqq fastbook import fastbook fastbook.setup_book() . Does some magic to setup my environment, here I&#39;m looking to see how hard it was to do this manually. The first thing I&#39;ll do is load up fastai instead of fastbook so I still have all the fastai libraries at hand if I need any core or helper functions . !rm -rf /content/sample_data/birds #cleanup for new run . !pip install -Uqq fastai . from fastai.vision.all import * . Running fastbook.setup_book?? showed that there was a boolean IN_COLLAB that called another function fastbook.setup_colab() to do the setup. Inside setup_collab it sets a global variable gdrive to my current path, and then imports google.collab to use drive to mount my google drive. I can do this myself here. . The snippets below are mostly straight out the fastbook source code in Github . global gdrive gdrive = Path(&#39;/content/gdrive/My Drive&#39;) from google.colab import drive if not gdrive.exists(): drive.mount(str(gdrive.parent)) . path = Path.cwd() . path . Path(&#39;/content&#39;) . There is also a nice little function for pulling images from Duck Duck Go instead of having to sign up to Microsoft Azure to get a key to use the Bing API for image search . def search_images_ddg(term, max_images=200): &quot;Search for `term` with DuckDuckGo and return a unique urls of about `max_images` images&quot; assert max_images&lt;1000 url = &#39;https://duckduckgo.com/&#39; res = urlread(url,data={&#39;q&#39;:term}) searchObj = re.search(r&#39;vqd=([ d-]+) &amp;&#39;, res) assert searchObj requestUrl = url + &#39;i.js&#39; params = dict(l=&#39;us-en&#39;, o=&#39;json&#39;, q=term, vqd=searchObj.group(1), f=&#39;,,,&#39;, p=&#39;1&#39;, v7exp=&#39;a&#39;) urls,data = set(),{&#39;next&#39;:1} while len(urls)&lt;max_images and &#39;next&#39; in data: try: data = urljson(requestUrl,data=params) urls.update(L(data[&#39;results&#39;]).itemgot(&#39;image&#39;)) requestUrl = url + data[&#39;next&#39;] except (URLError,HTTPError): pass time.sleep(0.2) return L(urls) . This code has a reference to an L object from fastcore, which in documentation on L indicates the intention of it is to replace lists. I should dive deeper into this to understand more. . I originally wrote a Trinidad hummingbird classifier from a previous attempt at the fastai course, in honor my native country of Trinidad and Tobago. This time, since I&#39;m now in Australia, and celebrating my 4th year as a Queenslander living in Brisbane, I wanted to take a look at classifying Brisbane birds. There are actually alot of them, I&#39;ll pick just a few that I actually have remembered seeing so I can do the data cleansing step with a fair level of confidence. I added three types of ducks as well, just to make it a little tougher I think, although I&#39;m not sure if I know the differences myself so we will see how my cleansing activities fare. The names are based on this list. Let&#39;s start with the most famous one, the kookaburra. . kookaburra_bird_images = search_images_ddg(&quot;laughing kookaburra bird&quot;) kookaburra_bird_images[0] . &#39;http://www.glenchilton.com/wp-content/uploads/2014/09/laughing_kookaburra_Ian-Montgomery-birdway-com-au.jpg&#39; . type(kookaburra_bird_images) . fastcore.foundation.L . type(kookaburra_bird_images[0]) . str . There&#39;s a method attrgot() that is used to extract the file names from a column when doing this with Bing in Lesson 2 I read up the documentation on and got further clarification on fastai forums here. Duck Duck Go returns just strings, so there&#39;s no need to extract a column attribute here. . path.ls() . (#3) [Path(&#39;/content/.config&#39;),Path(&#39;/content/gdrive&#39;),Path(&#39;/content/sample_data&#39;)] . dest = path/&#39;sample_data/kookaburra_bird.jpg&#39; download_url(kookaburra_bird_images[0], dest) . im = Image.open(dest) im.to_thumb(128,128) . brisbane_bird_types = &quot;kookaburra&quot;,&quot;magpie goose&quot;,&quot;australian white ibis&quot;, &quot;australian pelican&quot;, &quot;pacific black duck&quot;, &quot;plumed whistling duck&quot;, &quot;australian wood duck&quot; path = path/&#39;sample_data/birds&#39; path . Path(&#39;/content/sample_data/birds&#39;) . if not path.exists(): path.mkdir() path . Path(&#39;/content/sample_data/birds&#39;) . path.ls() . (#0) [] . It may take some time to run with the default of 200 images. . for o in brisbane_bird_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_ddg(f&#39;{o} bird&#39;) download_images(dest, urls=results) . Download of http://www.environment.nsw.gov.au/images/nature/white_ibisLg.jpg has failed after 5 retries Fix the download manually: $ mkdir -p /content/sample_data/birds/australian white ibis $ cd /content/sample_data/birds/australian white ibis $ wget -c http://www.environment.nsw.gov.au/images/nature/white_ibisLg.jpg $ tar xf white_ibisLg.jpg And re-run your code once the download is successful . Let&#39;s verify we got images as we expected . path.ls() . (#7) [Path(&#39;/content/sample_data/birds/kookaburra&#39;),Path(&#39;/content/sample_data/birds/magpie goose&#39;),Path(&#39;/content/sample_data/birds/australian pelican&#39;),Path(&#39;/content/sample_data/birds/australian white ibis&#39;),Path(&#39;/content/sample_data/birds/pacific black duck&#39;),Path(&#39;/content/sample_data/birds/plumed whistling duck&#39;),Path(&#39;/content/sample_data/birds/australian wood duck&#39;)] . !ls &quot;sample_data/birds&quot; . &#39;australian pelican&#39; kookaburra &#39;plumed whistling duck&#39; &#39;australian white ibis&#39; &#39;magpie goose&#39; &#39;australian wood duck&#39; &#39;pacific black duck&#39; . get_image_files?? . fns = get_image_files(path) fns . (#1735) [Path(&#39;/content/sample_data/birds/kookaburra/00000173.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000145.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000195.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000044.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000047.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000143.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000101.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000188.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000158.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000074.jpg&#39;)...] . len(fns) . 1735 . Check for the corrupt images . failed = verify_images(fns) failed . (#4) [Path(&#39;/content/sample_data/birds/kookaburra/00000034.jpg&#39;),Path(&#39;/content/sample_data/birds/kookaburra/00000217.jpg&#39;),Path(&#39;/content/sample_data/birds/australian pelican/00000240.jpg&#39;),Path(&#39;/content/sample_data/birds/australian white ibis/00000119.jpg&#39;)] . Remove corrupted images . failed.map(Path.unlink); . I&#39;m going to bring forward the steps to clean up the data here from the book before cleaning, since I&#39;m pretty sure some of these aren&#39;t going to be bird images so I want to get rid of them. Since we don&#39;t have a classifier yet, we&#39;re going to have to use ImagesCleaner to do this pre-training cleaning step . from fastai.vision.widgets import * . We need the widgets to do cleanup. Reference this forum post . We need to see how to browse the individual directories since I don&#39;t think ImagesCleaner gives that directory selector that the ImageClassifierCleaner module does, so let&#39;s peek at how that works . ImageClassifierCleaner?? . ImagesCleaner?? . path.cwd() . Path(&#39;/content&#39;) . path = Path(&#39;sample_data/birds&#39;) . path.ls() . (#7) [Path(&#39;sample_data/birds/kookaburra&#39;),Path(&#39;sample_data/birds/magpie goose&#39;),Path(&#39;sample_data/birds/australian pelican&#39;),Path(&#39;sample_data/birds/australian white ibis&#39;),Path(&#39;sample_data/birds/pacific black duck&#39;),Path(&#39;sample_data/birds/plumed whistling duck&#39;),Path(&#39;sample_data/birds/australian wood duck&#39;)] . Rerun the next three cells substituting the different categories of kookaburra with magpie goose,australian white ibis, australian pelican, pacific black duck, plumed whistling duck, australian wood duck to do some initial pre-training cleaning of possibly irrelevant images from search engine . fns_to_clean = get_image_files(path/&#39;kookaburra&#39;) fns_to_clean . (#234) [Path(&#39;sample_data/birds/kookaburra/00000173.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000145.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000195.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000044.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000047.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000143.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000101.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000188.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000158.jpg&#39;),Path(&#39;sample_data/birds/kookaburra/00000074.jpg&#39;)...] . cleaner = ImagesCleaner() cleaner.set_fns(fns_to_clean) cleaner . Now that we&#39;ve marked the ones that should get remove, let&#39;s take them out of the image data before we start training our model . for idx in cleaner.delete(): cleaner.fns[idx].unlink() . path.ls() . (#7) [Path(&#39;sample_data/birds/kookaburra&#39;),Path(&#39;sample_data/birds/magpie goose&#39;),Path(&#39;sample_data/birds/australian pelican&#39;),Path(&#39;sample_data/birds/australian white ibis&#39;),Path(&#39;sample_data/birds/pacific black duck&#39;),Path(&#39;sample_data/birds/plumed whistling duck&#39;),Path(&#39;sample_data/birds/australian wood duck&#39;)] . Load the data into the datablock . birds = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = birds.dataloaders(path) . dls.valid.show_batch(max_n=10, nrows=2) . Squishing large images to fit into the size of the image . birds = birds.new(item_tfms=Resize(128, ResizeMethod.Squish)) dls = birds.dataloaders(path) dls.valid.show_batch(max_n=10, nrows=2) . Padding the image borders so they fit . birds = birds.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;)) dls = birds.dataloaders(path) dls.valid.show_batch(max_n=10, nrows=2) . Randomly resizing images to allow it to learn on specific parts of an image during epoch . birds = birds.new(item_tfms=RandomResizedCrop(128, min_scale=0.3)) dls = birds.dataloaders(path) dls.train.show_batch(max_n=10, nrows=2, unique=True) . Starting the data augmentation step here, which does a randomization of all three previous steps. . TODO:Add the individual keywords for image rotation, flipping, perspective warping, brightness changes and contrast changes. . birds = birds.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2)) dls = birds.dataloaders(path) dls.train.show_batch(max_n=8, nrows=2, unique=True) . /usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release. torch.linalg.solve has its arguments reversed and does not return the LU factorization. To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack. X = torch.solve(B, A).solution should be replaced with X = torch.linalg.solve(A, B) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:760.) ret = func(*args, **kwargs) . Putting it all together now to train our model . birds = birds.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = birds.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.692304 | 0.229488 | 0.078035 | 00:46 | . epoch train_loss valid_loss error_rate time . 0 | 0.362119 | 0.178386 | 0.072254 | 00:47 | . 1 | 0.267956 | 0.136552 | 0.046243 | 00:46 | . 2 | 0.220220 | 0.170266 | 0.049133 | 00:47 | . 3 | 0.163554 | 0.166847 | 0.049133 | 00:47 | . Take a look at how well it did . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Let&#39;s see where it went wrong . interp.plot_top_losses(10, nrows=10) . If I missed some categorization pre-training, now I can use the code from the book to fix these mistakes here . cleaner = ImageClassifierCleaner(learn) cleaner . for idx in cleaner.delete(): cleaner.fns[idx].unlink() for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . I can now re-run the learner with the fixed dataset and see if that helps improve anything. I removed the young birds which looked starkly different to adults, as well as some pictures of eggs that were in the data, and some drawings that were not photos . learn.fine_tune(2) . epoch train_loss valid_loss error_rate time . 0 | 0.085772 | 0.138853 | 0.043353 | 00:47 | . epoch train_loss valid_loss error_rate time . 0 | 0.070127 | 0.155185 | 0.034682 | 00:48 | . 1 | 0.078726 | 0.142527 | 0.043353 | 00:47 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(10, nrows=10) . Possible improvement notes: . I need to learn what these birds actually look like by definition so I can fix the training data better | I may be running fine tune too many times as it seems to be starting to overfit, but need to read up more on this | Learning from my hummingbird app experience I need to investigate if male and female of a species have distinguishing characteristics that require them to have separate categories to allow for better training, as well as looking at chicks/ducklings/young birds characteristics since these may also be very different from how an adult in the species looks | . Next steps . Go through the steps for exporting the model and publishing to Binder | .",
            "url": "https://redditech.github.io/reddi-hacking/2021/06/22/_06_23_Messing_around_with_fastai.html",
            "relUrl": "/2021/06/22/_06_23_Messing_around_with_fastai.html",
            "date": " • Jun 22, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Getting Data From Kaggle",
            "content": "Introduction . Here I will play around with the Kaggle CLI to find an interesting competition, and load the data from it . This is a riff off my learning team blog post about getting specific data from Kaggle. You should reference it to understand the setups bit below for the why behind the instructions for setting up Kaggle-CLI and Fastai. Good links to reference: . Kaggle API documentation | . !pip install kaggle . Requirement already satisfied: kaggle in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (1.5.12) Requirement already satisfied: python-dateutil in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2.8.1) Requirement already satisfied: six&gt;=1.10 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (1.16.0) Requirement already satisfied: python-slugify in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (5.0.2) Requirement already satisfied: requests in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2.25.1) Requirement already satisfied: urllib3 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (1.26.4) Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (4.59.0) Requirement already satisfied: certifi in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from kaggle) (2021.5.30) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests-&gt;kaggle) (4.0.0) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests-&gt;kaggle) (2.10) . !mamba install -c fastchan fastai -y . __ __ __ __ / / / / / / / / ███████████████/ /██/ /██/ /██/ /████████████████████████ / / / / / ____ / / _/ _/ _/ o __, / _/ _____/ ` |/ ███╗ ███╗ █████╗ ███╗ ███╗██████╗ █████╗ ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗ ██╔████╔██║███████║██╔████╔██║██████╔╝███████║ ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║ ██║ ╚═╝ ██║██║ ██║██║ ╚═╝ ██║██████╔╝██║ ██║ ╚═╝ ╚═╝╚═╝ ╚═╝╚═╝ ╚═╝╚═════╝ ╚═╝ ╚═╝ mamba (0.13.0) supported by @QuantStack GitHub: https://github.com/mamba-org/mamba Twitter: https://twitter.com/QuantStack █████████████████████████████████████████████████████████████ Looking for: [&#39;fastai&#39;] pkgs/r/osx-64 [&gt; ] (--:--) No change pkgs/r/osx-64 [====================] (00m:00s) No change pkgs/main/osx-64 [=&gt; ] (--:--) No change pkgs/main/osx-64 [====================] (00m:00s) No change pkgs/main/noarch [=&gt; ] (--:--) No change pkgs/main/noarch [====================] (00m:00s) No change pkgs/r/noarch [&gt; ] (--:--) No change pkgs/r/noarch [====================] (00m:00s) No change fastchan/osx-64 [=&gt; ] (--:--) No change fastchan/osx-64 [====================] (00m:00s) No change fastchan/noarch [=&gt; ] (--:--) No change fastchan/noarch [====================] (00m:00s) No change Transaction Prefix: /usr/local/anaconda3/envs/fastai All requested packages already installed . Let&#39;s say I want to find some getting started competitions, Kaggle CLI let&#39;s you do keyword searches . !kaggle competitions list -s &quot;Getting Started&quot; . ref deadline category reward teamCount userHasEntered -- - -- tpu-getting-started 2030-06-03 23:59:00 Getting Started Knowledge 936 False nlp-getting-started 2030-01-01 00:00:00 Getting Started Knowledge 3171 False gan-getting-started 2030-07-01 23:59:00 Getting Started Prizes 321 False acm-sf-chapter-hackathon-small 2012-09-30 01:00:00 Research $600 96 False getting-started 2012-02-26 00:00:00 Featured $10,000 0 False street-view-getting-started-with-julia 2017-01-07 00:00:00 Getting Started Knowledge 56 False . I know there&#39;s a Titanic dataset, but it isn&#39;t found with keyword searching, so let&#39;s try the category . !kaggle competitions list --category &quot;Getting Started&quot; . Invalid category specified. Valid options are [&#39;all&#39;, &#39;featured&#39;, &#39;research&#39;, &#39;recruitment&#39;, &#39;gettingStarted&#39;, &#39;masters&#39;, &#39;playground&#39;] . !kaggle competitions list --category gettingStarted . ref deadline category reward teamCount userHasEntered - - -- contradictory-my-dear-watson 2030-07-01 23:59:00 Getting Started Prizes 188 False gan-getting-started 2030-07-01 23:59:00 Getting Started Prizes 321 False tpu-getting-started 2030-06-03 23:59:00 Getting Started Knowledge 936 False digit-recognizer 2030-01-01 00:00:00 Getting Started Knowledge 5879 True titanic 2030-01-01 00:00:00 Getting Started Knowledge 48369 False house-prices-advanced-regression-techniques 2030-01-01 00:00:00 Getting Started Knowledge 12623 True connectx 2030-01-01 00:00:00 Getting Started Knowledge 951 False nlp-getting-started 2030-01-01 00:00:00 Getting Started Knowledge 3171 False facial-keypoints-detection 2017-01-07 00:00:00 Getting Started Knowledge 175 False street-view-getting-started-with-julia 2017-01-07 00:00:00 Getting Started Knowledge 56 False word2vec-nlp-tutorial 2015-06-30 23:59:00 Getting Started Knowledge 577 False data-science-london-scikit-learn 2014-12-31 23:59:00 Getting Started Knowledge 190 False just-the-basics-the-after-party 2013-03-01 01:00:00 Getting Started Knowledge 48 False just-the-basics-strata-2013 2013-02-26 20:30:00 Getting Started Knowledge 49 False . There it is! This is where those fastai helper functions come in handy. I&#39;m going to work with tabular data, so I&#39;ll get this from the tabular library . from fastai.tabular.all import * . Path.cwd() . Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks&#39;) . Now I need to make sure I put this data in the correct place so it doesn&#39;t get checked in when I commit my changes in Github. I want to create a folder _data and have add an entry to my .gitignore to avoid the dataset I download into it from being checked in . !touch .gitignore . !echo &quot;_data&quot; &gt; .gitignore . !head .gitignore . _data . !mkdir _data . os.chdir(&#39;_data&#39;) Path.cwd() . Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks/_data&#39;) . Ok, looks like I&#39;m ready to download that Titanic dataset . !kaggle competitions download -c titanic . 403 - Forbidden . Ok, this was a head scratcher, but it looks like before I can download any dataset, I need to go to the competition page and join the competition and accept the rules. I should have read the documentation that said this. Usual format for competition URLs is https://www.kaggle.com/c/&lt;competition-name&gt;/rules . !kaggle competitions download -c titanic . Downloading titanic.zip to /Users/nissan/code/reddi-hacking/_notebooks/_data 0%| | 0.00/34.1k [00:00&lt;?, ?B/s] 100%|██████████████████████████████████████| 34.1k/34.1k [00:00&lt;00:00, 1.41MB/s] . Now let&#39;s verify the file is there, and extract the data . path = Path.cwd() path.ls() . (#1) [Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks/_data/titanic.zip&#39;)] . file_extract(&#39;titanic.zip&#39;) . path.ls() . (#4) [Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks/_data/test.csv&#39;),Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks/_data/titanic.zip&#39;),Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks/_data/train.csv&#39;),Path(&#39;/Users/nissan/code/reddi-hacking/_notebooks/_data/gender_submission.csv&#39;)] . Using the Kaggle API . After I wrote above, I just read a chapter of the book that showed the Kaggle API is available programmatically, so I can use this instead of command line to load the data, and since I already have the tabular libraries loaded and load and take a first look at the top rows of the data . from kaggle import api . api.competitions_list(category=&#39;gettingStarted&#39;) . [contradictory-my-dear-watson, gan-getting-started, tpu-getting-started, digit-recognizer, titanic, house-prices-advanced-regression-techniques, connectx, nlp-getting-started, facial-keypoints-detection, street-view-getting-started-with-julia, word2vec-nlp-tutorial, data-science-london-scikit-learn, just-the-basics-the-after-party, just-the-basics-strata-2013] . api.competition_download_cli(&#39;titanic&#39;, path=path) file_extract(&quot;titanic.zip&quot;) . titanic.zip: Skipping, found more recently modified local copy (use --force to force download) . df = pd.read_csv(path/&#39;train.csv&#39;, skipinitialspace=True) df.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | .",
            "url": "https://redditech.github.io/reddi-hacking/kaggle/2021/06/21/Getting-Data-In-Kaggle.html",
            "relUrl": "/kaggle/2021/06/21/Getting-Data-In-Kaggle.html",
            "date": " • Jun 21, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://redditech.github.io/reddi-hacking/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "Introduction . Messing around with various libraries from the fastbook notebooks. I want to do what fastbook_setup() does manually using fastai libraries directly. . !mamba install -c fastchan fastai -y . __ __ __ __ / / / / / / / / ███████████████/ /██/ /██/ /██/ /████████████████████████ / / / / / ____ / / _/ _/ _/ o __, / _/ _____/ ` |/ ███╗ ███╗ █████╗ ███╗ ███╗██████╗ █████╗ ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗ ██╔████╔██║███████║██╔████╔██║██████╔╝███████║ ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║ ██║ ╚═╝ ██║██║ ██║██║ ╚═╝ ██║██████╔╝██║ ██║ ╚═╝ ╚═╝╚═╝ ╚═╝╚═╝ ╚═╝╚═════╝ ╚═╝ ╚═╝ mamba (0.13.0) supported by @QuantStack GitHub: https://github.com/mamba-org/mamba Twitter: https://twitter.com/QuantStack █████████████████████████████████████████████████████████████ Looking for: [&#39;fastai&#39;] pkgs/main/osx-64 [=&gt; ] (--:--) No change pkgs/main/osx-64 [====================] (00m:00s) No change pkgs/main/noarch [=&gt; ] (--:--) No change pkgs/main/noarch [====================] (00m:00s) No change pkgs/r/osx-64 [=&gt; ] (--:--) No change pkgs/r/osx-64 [====================] (00m:00s) No change pkgs/r/noarch [=&gt; ] (--:--) No change pkgs/r/noarch [====================] (00m:00s) No change fastchan/noarch [&gt; ] (--:--) No change fastchan/noarch [====================] (00m:00s) No change fastchan/osx-64 [=&gt; ] (--:--) No change fastchan/osx-64 [====================] (00m:00s) No change Transaction Prefix: /usr/local/anaconda3/envs/fastai All requested packages already installed . Unwrapping fastbook.setup_book() . In my Colab notebook, running fastbook.setup_book?? showed that there was a boolean IN_COLLAB that called another function fastbook.setup_colab() to do the setup. Inside setup_collab it sets a global variable gdrive to my current path, and then imports google.collab to use drive to mount my google drive. I want google drive access in my locally running Jupyter too! Let&#39;s see what we can do. But the pip documentation for google.collab seems to imply this is Google Colab specific. . First time I said I&#39;d give it a go and still ran pip install google.colab on a Mac, it got stuck on the Building wheels for collected packages:pandas, numpy. . # !pip install google.colab --upgrade . I found this project by a member of the colab team that offers some hope for still mounting my google drive inside the notebook, and it seems to be recently updated so it&#39;s active, but it didn&#39;t have much else in terms of documentation so I wasn&#39;t able to use it. However, maybe it might get some documentation love soon in which case I&#39;d look at it again . !pip install gdrive . Collecting gdrive Downloading gdrive-0.0.8-py3-none-any.whl (7.2 kB) Collecting google-auth-oauthlib~=0.4.1 Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB) Collecting wheel~=0.32.3 Downloading wheel-0.32.3-py2.py3-none-any.whl (21 kB) Collecting pykeepass~=4.0.0 Downloading pykeepass-4.0.1.tar.gz (48 kB) |████████████████████████████████| 48 kB 5.3 MB/s eta 0:00:01 Collecting argparse~=1.4.0 Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB) Collecting setuptools~=56.0.0 Downloading setuptools-56.0.0-py3-none-any.whl (784 kB) |████████████████████████████████| 784 kB 8.5 MB/s eta 0:00:01 Collecting google-auth~=1.24.0 Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB) |████████████████████████████████| 114 kB 12.1 MB/s eta 0:00:01 Collecting google-api-python-client~=1.11.0 Downloading google_api_python_client-1.11.0-py2.py3-none-any.whl (60 kB) |████████████████████████████████| 60 kB 8.2 MB/s eta 0:00:01 Collecting versioneer~=0.19 Downloading versioneer-0.19-py3-none-any.whl (38 kB) Collecting SecretStorage~=3.2.0 Downloading SecretStorage-3.2.0-py3-none-any.whl (14 kB) Collecting google-auth-httplib2~=0.0.4 Downloading google_auth_httplib2-0.0.4-py2.py3-none-any.whl (9.1 kB) Requirement already satisfied: google-api-core&lt;2dev,&gt;=1.18.0 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-api-python-client~=1.11.0-&gt;gdrive) (1.25.1) Requirement already satisfied: six&lt;2dev,&gt;=1.6.1 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-api-python-client~=1.11.0-&gt;gdrive) (1.16.0) Collecting httplib2&lt;1dev,&gt;=0.9.2 Downloading httplib2-0.19.1-py3-none-any.whl (95 kB) |████████████████████████████████| 95 kB 8.6 MB/s eta 0:00:01 Collecting uritemplate&lt;4dev,&gt;=3.0.0 Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB) Requirement already satisfied: googleapis-common-protos&lt;2.0dev,&gt;=1.6.0 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (1.53.0) Requirement already satisfied: requests&lt;3.0.0dev,&gt;=2.18.0 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (2.25.1) Requirement already satisfied: protobuf&gt;=3.12.0 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (3.15.8) Requirement already satisfied: pytz in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (2021.1) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-auth~=1.24.0-&gt;gdrive) (4.2.2) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-auth~=1.24.0-&gt;gdrive) (0.2.8) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from google-auth~=1.24.0-&gt;gdrive) (4.7.2) Collecting requests-oauthlib&gt;=0.7.0 Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB) Requirement already satisfied: pyparsing&lt;3,&gt;=2.4.2 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from httplib2&lt;1dev,&gt;=0.9.2-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (2.4.7) Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth~=1.24.0-&gt;gdrive) (0.4.8) Requirement already satisfied: python-dateutil in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from pykeepass~=4.0.0-&gt;gdrive) (2.8.1) Collecting construct==2.10.54 Downloading construct-2.10.54.tar.gz (55 kB) |████████████████████████████████| 55 kB 6.6 MB/s eta 0:00:01 Requirement already satisfied: argon2_cffi in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from pykeepass~=4.0.0-&gt;gdrive) (20.1.0) Collecting pycryptodomex&gt;=3.6.2 Downloading pycryptodomex-3.10.1-cp35-abi3-macosx_10_9_x86_64.whl (1.5 MB) |████████████████████████████████| 1.5 MB 9.2 MB/s eta 0:00:01 Collecting lxml Downloading lxml-4.6.3-cp38-cp38-macosx_10_9_x86_64.whl (4.6 MB) |████████████████████████████████| 4.6 MB 11.0 MB/s eta 0:00:01 Collecting future Downloading future-0.18.2.tar.gz (829 kB) |████████████████████████████████| 829 kB 10.6 MB/s eta 0:00:01 Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (1.26.4) Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (4.0.0) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from requests&lt;3.0.0dev,&gt;=2.18.0-&gt;google-api-core&lt;2dev,&gt;=1.18.0-&gt;google-api-python-client~=1.11.0-&gt;gdrive) (2021.5.30) Collecting oauthlib&gt;=3.0.0 Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB) |████████████████████████████████| 146 kB 8.7 MB/s eta 0:00:01 Requirement already satisfied: cryptography&gt;=2.0 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from SecretStorage~=3.2.0-&gt;gdrive) (3.4.7) Collecting jeepney&gt;=0.4.2 Downloading jeepney-0.6.0-py3-none-any.whl (45 kB) |████████████████████████████████| 45 kB 7.0 MB/s eta 0:00:01 Requirement already satisfied: cffi&gt;=1.12 in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from cryptography&gt;=2.0-&gt;SecretStorage~=3.2.0-&gt;gdrive) (1.14.5) Requirement already satisfied: pycparser in /usr/local/anaconda3/envs/fastai/lib/python3.8/site-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=2.0-&gt;SecretStorage~=3.2.0-&gt;gdrive) (2.20) Building wheels for collected packages: pykeepass, construct, future Building wheel for pykeepass (setup.py) ... done Created wheel for pykeepass: filename=pykeepass-4.0.1-py3-none-any.whl size=49853 sha256=35d7f0ad3bafcd9a22340eb1b666a239121a289604d754af2e1f63ecbdf026ac Stored in directory: /Users/nissan/Library/Caches/pip/wheels/8f/b8/5d/3a4acb18d086a7411461a73f7055848c1f7348ded80ae3f522 Building wheel for construct (setup.py) ... done Created wheel for construct: filename=construct-2.10.54-py3-none-any.whl size=57401 sha256=43fb0fa26e21ff4774c946b62c669851748cafafea33e8e70877db8831e1b8bf Stored in directory: /Users/nissan/Library/Caches/pip/wheels/ec/47/0d/805b4b68ccdb5ab1b77bcd3f3be025fcc5e7070a245555dc28 Building wheel for future (setup.py) ... done Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=3cd9e25e99983208f848276932e07bd07e5f15c0e9c45d67c0cbb0df694d1b69 Stored in directory: /Users/nissan/Library/Caches/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4 Successfully built pykeepass construct future Installing collected packages: setuptools, oauthlib, httplib2, google-auth, uritemplate, requests-oauthlib, pycryptodomex, lxml, jeepney, google-auth-httplib2, future, construct, wheel, versioneer, SecretStorage, pykeepass, google-auth-oauthlib, google-api-python-client, argparse, gdrive Attempting uninstall: setuptools Found existing installation: setuptools 52.0.0.post20210125 Uninstalling setuptools-52.0.0.post20210125: Successfully uninstalled setuptools-52.0.0.post20210125 Attempting uninstall: google-auth Found existing installation: google-auth 1.21.3 Uninstalling google-auth-1.21.3: Successfully uninstalled google-auth-1.21.3 Attempting uninstall: wheel Found existing installation: wheel 0.36.2 Uninstalling wheel-0.36.2: Successfully uninstalled wheel-0.36.2 Successfully installed SecretStorage-3.2.0 argparse-1.4.0 construct-2.10.54 future-0.18.2 gdrive-0.0.8 google-api-python-client-1.11.0 google-auth-1.24.0 google-auth-httplib2-0.0.4 google-auth-oauthlib-0.4.4 httplib2-0.19.1 jeepney-0.6.0 lxml-4.6.3 oauthlib-3.1.1 pycryptodomex-3.10.1 pykeepass-4.0.1 requests-oauthlib-1.3.0 setuptools-56.0.0 uritemplate-3.0.1 versioneer-0.19 wheel-0.32.3 . Let&#39;s see if I can view my kaggle.json configuration . from gdrive import * . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://redditech.github.io/reddi-hacking/jupyter/2020/02/20/test-Copy1.html",
            "relUrl": "/jupyter/2020/02/20/test-Copy1.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://redditech.github.io/reddi-hacking/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://redditech.github.io/reddi-hacking/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://redditech.github.io/reddi-hacking/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}